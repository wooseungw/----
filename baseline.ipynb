{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85636527-d0a6-4d46-9481-8f9f5d9c657b",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "146d3550-a0d9-4602-9c09-222953286b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import GPT2LMHeadModel, PreTrainedTokenizerFast, AdamW\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2eccd5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# CUDA 사용 가능 여부 확인\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9900567-97b6-45ee-a00b-813035d9eb26",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cadc43a-1acf-461e-b19b-44314861a27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n",
      "644it [00:01, 555.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 데이터 로드\n",
    "data = pd.read_csv('train.csv')\n",
    "\n",
    "# 토크나이저 로드\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained('skt/kogpt2-base-v2', eos_token='</s>')\n",
    "\n",
    "# 데이터 포맷팅 및 토크나이징\n",
    "formatted_data = []\n",
    "for _, row in tqdm(data.iterrows()):\n",
    "    for q_col in ['질문_1', '질문_2']:\n",
    "        for a_col in ['답변_1', '답변_2', '답변_3', '답변_4', '답변_5']:\n",
    "            # 질문과 답변 쌍을 </s> token으로 연결\n",
    "            input_text = row[q_col] + tokenizer.eos_token + row[a_col]\n",
    "            input_ids = tokenizer.encode(input_text, return_tensors='pt')\n",
    "            formatted_data.append(input_ids)\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4105cb04-bc9c-4bb5-8230-cbd84f34d4fb",
   "metadata": {},
   "source": [
    "## Model Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cf4940-6155-43ac-9315-2a17e56a06b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 로드\n",
    "model = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2')\n",
    "model.to(device) # 모델을 GPU단으로 이동\n",
    "\n",
    "# 모델 학습 하이퍼파라미터(Hyperparameter) 세팅\n",
    "# 실제 필요에 따라 조정하세요.\n",
    "CFG = {\n",
    "    'LR' : 2e-5, # Learning Rate\n",
    "    'EPOCHS' : 10, # 학습 Epoch\n",
    "}\n",
    "\n",
    "# 모델 학습 설정\n",
    "optimizer = AdamW(model.parameters(), lr=CFG['LR'])\n",
    "model.train()\n",
    "\n",
    "# 모델 학습\n",
    "for epoch in range(CFG['EPOCHS']):\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(enumerate(formatted_data), total=len(formatted_data))\n",
    "    for batch_idx, batch in progress_bar:\n",
    "        # 데이터를 GPU단으로 이동\n",
    "        batch = batch.to(device)\n",
    "        outputs = model(batch, labels=batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # 진행률 표시줄에 평균 손실 업데이트\n",
    "        progress_bar.set_description(f\"Epoch {epoch+1} - Avg Loss: {total_loss / (batch_idx+1):.4f}\")\n",
    "\n",
    "    # 에폭의 평균 손실을 출력\n",
    "    print(f\"Epoch {epoch+1}/{CFG['EPOCHS']}, Average Loss: {total_loss / len(formatted_data)}\")\n",
    "\n",
    "# 모델 저장\n",
    "model.save_pretrained(\"./hansoldeco-kogpt2\")\n",
    "tokenizer.save_pretrained(\"./hansoldeco-kogpt2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bf12d4-544a-4f4c-b5ab-5e7bce2a42cb",
   "metadata": {},
   "source": [
    "## Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06d4a374",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 130/130 [05:02<00:00,  2.33s/it]\n"
     ]
    }
   ],
   "source": [
    "# 저장된 Fine-tuned 모델과 토크나이저 불러오기\n",
    "model_dir = \"./hansoldeco-kogpt2\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_dir)\n",
    "model.to(device)\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(model_dir)\n",
    "\n",
    "# Inference를 위한 test.csv 파일 로드\n",
    "test = pd.read_csv('./test.csv')\n",
    "\n",
    "# test.csv의 '질문'에 대한 '답변'을 저장할 리스트\n",
    "preds = []\n",
    "\n",
    "# '질문' 컬럼의 각 질문에 대해 답변 생성\n",
    "for test_question in tqdm(test['질문']):\n",
    "    # 입력 텍스트를 토큰화하고 모델 입력 형태로 변환\n",
    "    input_ids = tokenizer.encode(test_question + tokenizer.eos_token, return_tensors='pt')\n",
    "\n",
    "    # 답변 생성\n",
    "    output_sequences = model.generate(\n",
    "        input_ids=input_ids.to(device),\n",
    "        max_length=300,\n",
    "        temperature=0.9,\n",
    "        top_k=1,\n",
    "        top_p=0.9,\n",
    "        repetition_penalty=1.2,\n",
    "        do_sample=True,\n",
    "        num_return_sequences=1\n",
    "    )\n",
    "\n",
    "    # 생성된 텍스트(답변) 저장\n",
    "    for generated_sequence in output_sequences:\n",
    "        full_text = tokenizer.decode(generated_sequence, skip_special_tokens=False)\n",
    "        # 질문과 답변의 사이를 나타내는 eos_token (</s>)를 찾아, 이후부터 출력\n",
    "        answer_start = full_text.find(tokenizer.eos_token) + len(tokenizer.eos_token)\n",
    "        answer_only = full_text[answer_start:].strip()\n",
    "        answer_only = answer_only.replace('\\n', ' ')\n",
    "        preds.append(answer_only)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188a2dd5-5179-40db-b300-16d58706e18e",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ced0f6d3-8edf-4ccd-8901-9782007a8621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130, 512)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test 데이터셋의 모든 질의에 대한 답변으로부터 512 차원의 Embedding Vector 추출\n",
    "# 평가를 위한 Embedding Vector 추출에 활용하는 모델은 'distiluse-base-multilingual-cased-v1' 이므로 반드시 확인해주세요.\n",
    "from sentence_transformers import SentenceTransformer # SentenceTransformer Version 2.2.2\n",
    "\n",
    "# Embedding Vector 추출에 활용할 모델(distiluse-base-multilingual-cased-v1) 불러오기\n",
    "model = SentenceTransformer('distiluse-base-multilingual-cased-v1')\n",
    "\n",
    "# 생성한 모든 응답(답변)으로부터 Embedding Vector 추출\n",
    "pred_embeddings = model.encode(preds)\n",
    "pred_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d1069adf-e9c0-46d9-bbee-9f7b4a9dc091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>vec_0</th>\n",
       "      <th>vec_1</th>\n",
       "      <th>vec_2</th>\n",
       "      <th>vec_3</th>\n",
       "      <th>vec_4</th>\n",
       "      <th>vec_5</th>\n",
       "      <th>vec_6</th>\n",
       "      <th>vec_7</th>\n",
       "      <th>vec_8</th>\n",
       "      <th>...</th>\n",
       "      <th>vec_502</th>\n",
       "      <th>vec_503</th>\n",
       "      <th>vec_504</th>\n",
       "      <th>vec_505</th>\n",
       "      <th>vec_506</th>\n",
       "      <th>vec_507</th>\n",
       "      <th>vec_508</th>\n",
       "      <th>vec_509</th>\n",
       "      <th>vec_510</th>\n",
       "      <th>vec_511</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_000</td>\n",
       "      <td>-0.008283</td>\n",
       "      <td>0.006244</td>\n",
       "      <td>-0.050783</td>\n",
       "      <td>0.031482</td>\n",
       "      <td>0.100462</td>\n",
       "      <td>-0.028517</td>\n",
       "      <td>0.052007</td>\n",
       "      <td>0.015777</td>\n",
       "      <td>0.018285</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003769</td>\n",
       "      <td>-0.042816</td>\n",
       "      <td>0.034695</td>\n",
       "      <td>-0.021159</td>\n",
       "      <td>0.037977</td>\n",
       "      <td>0.114959</td>\n",
       "      <td>-0.008681</td>\n",
       "      <td>-0.050804</td>\n",
       "      <td>-0.015067</td>\n",
       "      <td>-0.008490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_001</td>\n",
       "      <td>0.003960</td>\n",
       "      <td>0.022965</td>\n",
       "      <td>-0.082703</td>\n",
       "      <td>0.033952</td>\n",
       "      <td>0.083040</td>\n",
       "      <td>-0.028981</td>\n",
       "      <td>0.015447</td>\n",
       "      <td>-0.020635</td>\n",
       "      <td>0.012197</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008174</td>\n",
       "      <td>-0.021418</td>\n",
       "      <td>-0.001662</td>\n",
       "      <td>-0.056054</td>\n",
       "      <td>-0.029672</td>\n",
       "      <td>0.036788</td>\n",
       "      <td>0.005357</td>\n",
       "      <td>-0.029781</td>\n",
       "      <td>-0.031500</td>\n",
       "      <td>0.013643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_002</td>\n",
       "      <td>-0.020980</td>\n",
       "      <td>-0.007395</td>\n",
       "      <td>0.002687</td>\n",
       "      <td>0.028833</td>\n",
       "      <td>0.079106</td>\n",
       "      <td>0.000619</td>\n",
       "      <td>-0.032760</td>\n",
       "      <td>-0.009004</td>\n",
       "      <td>-0.033658</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008491</td>\n",
       "      <td>-0.009477</td>\n",
       "      <td>0.029528</td>\n",
       "      <td>-0.044449</td>\n",
       "      <td>0.002459</td>\n",
       "      <td>0.074473</td>\n",
       "      <td>0.014259</td>\n",
       "      <td>-0.077537</td>\n",
       "      <td>0.012425</td>\n",
       "      <td>0.072127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_003</td>\n",
       "      <td>-0.036245</td>\n",
       "      <td>-0.009808</td>\n",
       "      <td>-0.061265</td>\n",
       "      <td>0.060713</td>\n",
       "      <td>0.124495</td>\n",
       "      <td>-0.022595</td>\n",
       "      <td>0.032668</td>\n",
       "      <td>0.048201</td>\n",
       "      <td>-0.007225</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022874</td>\n",
       "      <td>-0.060723</td>\n",
       "      <td>0.054093</td>\n",
       "      <td>-0.030370</td>\n",
       "      <td>0.016057</td>\n",
       "      <td>0.092961</td>\n",
       "      <td>-0.017627</td>\n",
       "      <td>-0.019150</td>\n",
       "      <td>0.015420</td>\n",
       "      <td>0.106604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_004</td>\n",
       "      <td>0.042974</td>\n",
       "      <td>0.053689</td>\n",
       "      <td>-0.086168</td>\n",
       "      <td>0.021497</td>\n",
       "      <td>0.080961</td>\n",
       "      <td>-0.015000</td>\n",
       "      <td>-0.010511</td>\n",
       "      <td>-0.010412</td>\n",
       "      <td>0.027915</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015654</td>\n",
       "      <td>-0.037026</td>\n",
       "      <td>-0.017417</td>\n",
       "      <td>-0.073782</td>\n",
       "      <td>-0.018489</td>\n",
       "      <td>0.018804</td>\n",
       "      <td>-0.005215</td>\n",
       "      <td>-0.041950</td>\n",
       "      <td>-0.026034</td>\n",
       "      <td>-0.011682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 513 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id     vec_0     vec_1     vec_2     vec_3     vec_4     vec_5  \\\n",
       "0  TEST_000 -0.008283  0.006244 -0.050783  0.031482  0.100462 -0.028517   \n",
       "1  TEST_001  0.003960  0.022965 -0.082703  0.033952  0.083040 -0.028981   \n",
       "2  TEST_002 -0.020980 -0.007395  0.002687  0.028833  0.079106  0.000619   \n",
       "3  TEST_003 -0.036245 -0.009808 -0.061265  0.060713  0.124495 -0.022595   \n",
       "4  TEST_004  0.042974  0.053689 -0.086168  0.021497  0.080961 -0.015000   \n",
       "\n",
       "      vec_6     vec_7     vec_8  ...   vec_502   vec_503   vec_504   vec_505  \\\n",
       "0  0.052007  0.015777  0.018285  ... -0.003769 -0.042816  0.034695 -0.021159   \n",
       "1  0.015447 -0.020635  0.012197  ... -0.008174 -0.021418 -0.001662 -0.056054   \n",
       "2 -0.032760 -0.009004 -0.033658  ...  0.008491 -0.009477  0.029528 -0.044449   \n",
       "3  0.032668  0.048201 -0.007225  ... -0.022874 -0.060723  0.054093 -0.030370   \n",
       "4 -0.010511 -0.010412  0.027915  ... -0.015654 -0.037026 -0.017417 -0.073782   \n",
       "\n",
       "    vec_506   vec_507   vec_508   vec_509   vec_510   vec_511  \n",
       "0  0.037977  0.114959 -0.008681 -0.050804 -0.015067 -0.008490  \n",
       "1 -0.029672  0.036788  0.005357 -0.029781 -0.031500  0.013643  \n",
       "2  0.002459  0.074473  0.014259 -0.077537  0.012425  0.072127  \n",
       "3  0.016057  0.092961 -0.017627 -0.019150  0.015420  0.106604  \n",
       "4 -0.018489  0.018804 -0.005215 -0.041950 -0.026034 -0.011682  \n",
       "\n",
       "[5 rows x 513 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit = pd.read_csv('./sample_submission.csv')\n",
    "# 제출 양식 파일(sample_submission.csv)을 활용하여 Embedding Vector로 변환한 결과를 삽입\n",
    "submit.iloc[:,1:] = pred_embeddings\n",
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d22c4259-c43e-4e2f-9456-d15f249370d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 리더보드 제출을 위한 csv파일 생성\n",
    "submit.to_csv('./baseline_submit.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gimin_py38",
   "language": "python",
   "name": "gimin_py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
